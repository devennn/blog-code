{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import string\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\n",
    "test_df = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\n",
    "train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(tweet_text, df):\n",
    "    temp = []\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    for tweet in tweet_text:\n",
    "        # Remove links\n",
    "        tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "        # Remove newline\n",
    "        tweet = tweet.strip('\\n')\n",
    "        # Remove unicode\n",
    "        tweet = normalize('NFKD', tweet).encode('ascii','ignore')\n",
    "        # Remove username\n",
    "        tweet = re.sub('@[^\\s]+','',str(tweet))\n",
    "        # Remove punctuation and change to lower case\n",
    "        tweet = tweet.translate(table).lower()\n",
    "        # Remove 'b' at the begining for binary\n",
    "        tweet = tweet.replace('b', '', 1)\n",
    "        # Remove whitespace at start of sentence\n",
    "        tweet = tweet.strip()\n",
    "#         # Remove numbers\n",
    "#         tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
    "        temp.append(tweet)\n",
    "    try:\n",
    "        # Concatenate training with target\n",
    "        processed_tweets = pd.concat([pd.DataFrame(temp), df['target']], axis=1)\n",
    "        processed_tweets = pd.DataFrame(processed_tweets)\n",
    "    except KeyError:\n",
    "        processed_tweets = pd.DataFrame(temp)\n",
    "#     print(processed_tweets)\n",
    "    return processed_tweets   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rockyfire update  california hwy 20 closed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flood disaster heavy rain causes flash floodin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>im on top of the hill and i can see a fire in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>theres an emergency evacuation happening now i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im afraid that the tornado is coming to our area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  target\n",
       "0  our deeds are the reason of this earthquake ma...       1\n",
       "1              forest fire near la ronge sask canada       1\n",
       "2  all residents asked to shelter in place are be...       1\n",
       "3  13000 people receive wildfires evacuation orde...       1\n",
       "4  just got sent this photo from ruby alaska as s...       1\n",
       "5  rockyfire update  california hwy 20 closed in ...       1\n",
       "6  flood disaster heavy rain causes flash floodin...       1\n",
       "7  im on top of the hill and i can see a fire in ...       1\n",
       "8  theres an emergency evacuation happening now i...       1\n",
       "9   im afraid that the tornado is coming to our area       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess training and testing tweets\n",
    "processed_tr_tweets = cleaning(train_df['text'], train_df)\n",
    "processed_tst_tweets = cleaning(test_df['text'], test_df)\n",
    "\n",
    "processed_tr_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target occurences\n",
    "\n",
    "processed_tr_tweets['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tweets(count_vect, data):\n",
    "    vect_tweets = count_vect.fit_transform(data)\n",
    "    print(type(vect_tweets))\n",
    "    vect_tweets = vect_tweets.toarray()\n",
    "    return vect_tweets, count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "length of Vocabulary: 19789\n",
      "Training length: 7613\n",
      "Testing length: 3263\n",
      "Length of train + test: 10876\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "count_vect = CountVectorizer(analyzer='word', lowercase=False, stop_words='english')\n",
    "# Combine both train and test\n",
    "# Prevent unequal length of variables after tokenization\n",
    "combined_tr_tst = pd.concat([processed_tr_tweets[0], processed_tst_tweets[0]], axis=0)\n",
    "combined_vect, count_vect = vectorize_tweets(count_vect, combined_tr_tst)\n",
    "print('length of Vocabulary: {}'.format(len(count_vect.vocabulary_)))\n",
    "\n",
    "# Check length\n",
    "len_tr = len(processed_tr_tweets[0])\n",
    "print('Training length: %d' %len_tr)\n",
    "len_tst = len(processed_tst_tweets[0])\n",
    "print('Testing length: %d' %len_tst)\n",
    "print('Length of train + test: %d' %len(combined_vect))\n",
    "\n",
    "# Split back to train and test\n",
    "vect_tweets = combined_vect[:len_tr]\n",
    "vect_tst_tweets = combined_vect[len_tr:]\n",
    "\n",
    "print(vect_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        vect_tweets, \n",
    "        processed_tr_tweets['target'],\n",
    "        train_size=0.80, \n",
    "        random_state=True,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model_rg = LogisticRegression(solver='liblinear')\n",
    "model_rg = model_rg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n",
      "0.8036769533814839\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = model_rg.predict(X_test)\n",
    "print(len(y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-73fc039730ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean abs error Training : %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_cv' is not defined"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "param_grid = {\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag', 'saga', 'liblinear']\n",
    "}\n",
    "gs = GridSearchCV(model, param_grid, n_jobs=4, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(_cv.best_params_)\n",
    "mse = mean_absolute_error(y_train, gs_cv.predict(X_train))\n",
    "print(\"Mean abs error Training : %.4f\" % mse)\n",
    "mse = mean_absolute_error(y_test, gs_cv.predict(X_test))\n",
    "print(\"Mean abs error Training : %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  0\n",
      "0         0  1\n",
      "1         2  1\n",
      "2         3  1\n",
      "3         9  1\n",
      "4        11  1\n",
      "...     ... ..\n",
      "3258  10861  1\n",
      "3259  10865  1\n",
      "3260  10868  1\n",
      "3261  10874  1\n",
      "3262  10875  0\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "new_prediction = model_rg.predict(vect_tst_tweets)\n",
    "new_prediction = pd.DataFrame(new_prediction)\n",
    "new_prediction = pd.concat([test_df['id'], new_prediction], axis=1)\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  target\n",
      "0         0       1\n",
      "1         2       1\n",
      "2         3       1\n",
      "3         9       1\n",
      "4        11       1\n",
      "...     ...     ...\n",
      "3258  10861       1\n",
      "3259  10865       1\n",
      "3260  10868       1\n",
      "3261  10874       1\n",
      "3262  10875       0\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def save_submission(new_prediction, fname):\n",
    "    new_prediction = new_prediction.rename({0: 'target'}, axis=1) \n",
    "    new_prediction.to_csv(fname, index=False)\n",
    "    print(new_prediction)\n",
    "\n",
    "save_submission(new_prediction, 'submission2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import optimizers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_len, output_len):\n",
    "    n_hidden_1 = math.ceil(input_len / 2)\n",
    "    n_hidden_2 = math.ceil(n_hidden_1 / 2)\n",
    "    n_hidden_3 = n_hidden_2\n",
    "    n_hidden_4 = math.ceil(input_len / 2)\n",
    "\n",
    "    Inp = Input(shape=(input_len, ))\n",
    "    x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "    output = Dense(output_len, activation='softmax', name = \"Output_Layer\")(x)\n",
    "                \n",
    "    model = Model(Inp, output)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 19789)]           0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 9895)              195822050 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9895)              0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 4948)              48965408  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4948)              0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 4948)              24487652  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4948)              0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 9895)              48970355  \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 2)                 19792     \n",
      "=================================================================\n",
      "Total params: 318,265,257\n",
      "Trainable params: 318,265,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_len = X_train.shape[1]\n",
    "model = define_model(input_len, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, X_test, y_train, y_test):\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.1\n",
    "    adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size = 100,\n",
    "            epochs = 1,\n",
    "            validation_data=(X_test, y_test),\n",
    "            shuffle=True\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6090 samples, validate on 1523 samples\n",
      "6090/6090 [==============================] - 150s 25ms/sample - loss: 0.5868 - accuracy: 0.7227 - val_loss: 0.4648 - val_accuracy: 0.8083\n"
     ]
    }
   ],
   "source": [
    "y_train_np = y_train.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "model = train(model, X_train, X_test, y_train_np, y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "3258  0\n",
      "3259  0\n",
      "3260  0\n",
      "3261  0\n",
      "3262  0\n",
      "\n",
      "[3263 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "dl_predictions = pd.DataFrame(model.predict(vect_tst_tweets))\n",
    "dl_rounded = pd.DataFrame([int(x) for x in dl_predictions[1]])\n",
    "print(dl_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  0\n",
      "0         0  0\n",
      "1         2  0\n",
      "2         3  0\n",
      "3         9  0\n",
      "4        11  0\n",
      "...     ... ..\n",
      "3258  10861  0\n",
      "3259  10865  0\n",
      "3260  10868  0\n",
      "3261  10874  0\n",
      "3262  10875  0\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "format_predictions = pd.concat([test_df['id'], dl_rounded], axis=1)\n",
    "print(format_predictions)\n",
    "\n",
    "# save_submission(format_predictions, 'submission3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
